{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []# 保存样本集的列表\n",
    "for i in range(100): # 循环采样 100 个点\n",
    "    x = np.random.uniform(-10., 10.) # 随机采样输入 x\n",
    "    # 采样高斯噪声\n",
    "    eps = np.random.normal(0., 0.1)\n",
    "     # 得到模型的输出\n",
    "    y = 1.477 * x + 0.089 + eps\n",
    "    data.append([x, y]) # 保存样本点\n",
    "data = np.array(data) # 转换为 2D Numpy 数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(b, w, points):\n",
    "    # 根据当前的 w,b 参数计算均方差损失\n",
    "    totalError = 0\n",
    "    for i in range(0, len(points)): # 循环迭代所有点\n",
    "        x = points[i, 0] # 获得 i 号点的输入 x\n",
    "        y = points[i, 1] # 获得 i 号点的输出 y\n",
    "        # 计算差的平方，并累加\n",
    "        totalError += (y - (w * x + b)) ** 2\n",
    "        # 将累加的误差求平均，得到均方差\n",
    "    return totalError / float(len(points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_gradient(b_current, w_current, points, lr):\n",
    "    # 计算误差函数在所有点上的导数，并更新 w,b\n",
    "    b_gradient = 0\n",
    "    w_gradient = 0\n",
    "    M = float(len(points)) # 总样本数\n",
    "    for i in range(0, len(points)):\n",
    "        x = points[i, 0]\n",
    "        y = points[i, 1]\n",
    "        # 误差函数对 b 的导数：grad_b = 2(wx+b-y)，参考公式(2.3)\n",
    "        b_gradient += (2/M) * ((w_current * x + b_current) - y)\n",
    "        # 误差函数对 w 的导数：grad_w = 2(wx+b-y)*x，参考公式(2.2)\n",
    "        w_gradient += (2/M) * x * ((w_current * x + b_current) - y)\n",
    "    # 根据梯度下降算法更新 w',b',其中 lr 为学习率\n",
    "    new_b = b_current - (lr * b_gradient)\n",
    "    new_w = w_current - (lr * w_gradient)\n",
    "    return [new_b, new_w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(points, starting_b, starting_w, lr, num_iterations):\n",
    "    # 循环更新 w,b 多次\n",
    "    b = starting_b # b 的初始值\n",
    "    w = starting_w # w 的初始值\n",
    "    # 根据梯度下降算法更新多次\n",
    "    for step in range(num_iterations):\n",
    "        # 计算梯度并更新一次\n",
    "        b, w = step_gradient(b, w, np.array(points), lr)\n",
    "        loss = mse(b, w, points) # 计算当前的均方差，用于监控训练进度\n",
    "        if step%100 == 0: # 打印误差和实时的 w,b 值\n",
    "            print(f\"iteration:{step}, loss:{loss}, w:{w}, b:{b}\")\n",
    "    return [b, w, loss] # 返回最后一次的 w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # 加载训练集数据，这些数据是通过真实模型添加观测误差采样得到的\n",
    "    lr = 0.01 # 学习率\n",
    "    initial_b = 0 # 初始化 b 为 0\n",
    "    initial_w = 0 # 初始化 w 为 0\n",
    "    num_iterations = 1000\n",
    "    # 训练优化 1000 次，返回最优 w*,b*和训练 Loss 的下降过程\n",
    "    [b, w, losses] = gradient_descent(data, initial_b, initial_w, lr, num_iterations)\n",
    "    loss = mse(b, w, data) # 计算最优数值解 w,b 上的均方差\n",
    "    print(f'Final loss:{loss}, w:{w}, b:{b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:0, loss:5.894338716717385, w:1.0726397789740287, b:-0.004050151985176433\n",
      "iteration:100, loss:0.010912161609319333, w:1.4749808830711897, b:0.07376031143046227\n",
      "iteration:200, loss:0.01076447273973825, w:1.4750397091385805, b:0.08439771115513933\n",
      "iteration:300, loss:0.01076186370158084, w:1.4750475278673594, b:0.08581155619101284\n",
      "iteration:400, loss:0.010761817610903002, w:1.4750485670753573, b:0.0859994740879803\n",
      "iteration:500, loss:0.010761816796675532, w:1.475048705199251, b:0.08602445075452056\n",
      "iteration:600, loss:0.01076181678229159, w:1.4750487235576644, b:0.08602777046957451\n",
      "iteration:700, loss:0.010761816782037487, w:1.4750487259977298, b:0.08602821170171504\n",
      "iteration:800, loss:0.010761816782032975, w:1.4750487263220453, b:0.08602827034705014\n",
      "iteration:900, loss:0.010761816782032897, w:1.475048726365151, b:0.08602827814175724\n",
      "Final loss:0.010761816782032892, w:1.4750487263708625, b:0.08602827917453508\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
